{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# PRACTICA 1: ExtracciÃ³n de datos de una red social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "CLIENT_ID=\"\"\n",
    "CLIENT_SECRET=\"\"\n",
    "\n",
    "echo \"\n",
    "\n",
    "[tgine]\n",
    "client_id=$CLIENT_ID\n",
    "client_secret=$CLIENT_SECRET\n",
    "\" >> praw.ini"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import praw\n",
    "import json\n",
    "import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "from whoosh.index import create_in, open_dir\n",
    "from whoosh.fields import Schema, TEXT, ID, BOOLEAN\n",
    "from whoosh.qparser import QueryParser"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subreddit_display_name = \"science\"\n",
    "collections_dir = \"collections\"\n",
    "collection_names = [\"new\", \"hot\", \"rising\"]\n",
    "reddit_client_user_agent = \"python:com.example.gonzalocl1024.tgine:v1.0 (by /u/gonzalocl1024)\"\n",
    "\n",
    "min_document_frequency = 10\n",
    "most_central_terms = 50\n",
    "most_repeated = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subreddit_attributes = [\n",
    "    \"display_name\",\n",
    "    \"title\",\n",
    "    \"active_user_count\",\n",
    "    \"subscribers\",\n",
    "    \"id\",\n",
    "    \"description\",\n",
    "    \"created_utc\",\n",
    "    \"name\"\n",
    "]\n",
    "\n",
    "submission_attributes = [\n",
    "    \"title\",\n",
    "    \"name\",\n",
    "    \"upvote_ratio\",\n",
    "    \"ups\",\n",
    "    \"score\",\n",
    "    \"id\",\n",
    "    \"created_utc\",\n",
    "    \"selftext\",\n",
    "    \"downs\",\n",
    "    \"url\"\n",
    "]\n",
    "\n",
    "comment_attributes = [\n",
    "    \"ups\",\n",
    "    \"id\",\n",
    "    \"score\",\n",
    "    \"body\",\n",
    "    \"downs\"\n",
    "]\n",
    "\n",
    "def copy_attributes(dest, src, attributes):\n",
    "    for attribute in attributes:\n",
    "        try:\n",
    "            dest[attribute] = src[attribute]\n",
    "        except KeyError:\n",
    "            i = None\n",
    "            n = None\n",
    "            try:\n",
    "                i = src[\"id\"]\n",
    "            except KeyError:\n",
    "                pass\n",
    "            try:\n",
    "                n = src[\"name\"]\n",
    "            except KeyError:\n",
    "                pass\n",
    "            print(\"\\n{}, {}, {}\".format(attribute, i, n))\n",
    "\n",
    "def copy_subreddit(subreddit):\n",
    "    dest = {}\n",
    "    copy_attributes(dest, subreddit, subreddit_attributes)\n",
    "    return dest\n",
    "\n",
    "def copy_submission(submission):\n",
    "    dest = {}\n",
    "    copy_attributes(dest, submission, submission_attributes)\n",
    "    return dest\n",
    "\n",
    "def copy_comment(comment):\n",
    "    dest = {}\n",
    "    copy_attributes(dest, comment, comment_attributes)\n",
    "    return dest\n",
    "\n",
    "def copy_author(dest, src):\n",
    "    if src.author:\n",
    "        dest[\"author\"] = src.author.name\n",
    "    else:\n",
    "        dest[\"author\"] = None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Defino dos funciones una para obtener todos los _submissions_ en una lista y otra para obtener todos los comentarios de cada _submissions_."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def retrieve_submissions(submissions):\n",
    "\n",
    "    submission_list = []\n",
    "    i = 0\n",
    "\n",
    "    for submission in submissions:\n",
    "        submission_list.append(submission)\n",
    "\n",
    "        i += 1\n",
    "        print(\"\\rRetrieved submissions: {}\".format(i), end=\"\")\n",
    "\n",
    "    print()\n",
    "    return submission_list\n",
    "\n",
    "def retrieve_comments(collection, submissions):\n",
    "\n",
    "    i = 0\n",
    "    total_submissions = len(submissions)\n",
    "    total_comments = 0\n",
    "\n",
    "    collection[\"submissions\"] = []\n",
    "\n",
    "    for submission in submissions:\n",
    "\n",
    "        _ = submission.title\n",
    "        submission_copy = copy_submission(vars(submission))\n",
    "        copy_author(submission_copy, submission)\n",
    "\n",
    "        print(\" Next comment batch: {:<35}\".format(submission.num_comments), end=\"\")\n",
    "\n",
    "        comments = []\n",
    "        submission.comments.replace_more(limit=None)\n",
    "\n",
    "        for comment in submission.comments.list():\n",
    "            _ = comment.body\n",
    "            comment_copy = copy_comment(vars(comment))\n",
    "            copy_author(comment_copy, comment)\n",
    "            comments.append(comment_copy)\n",
    "\n",
    "        collection[\"submissions\"].append({\n",
    "            \"submission\": submission_copy,\n",
    "            \"comments\": comments\n",
    "        })\n",
    "\n",
    "        i += 1\n",
    "        total_comments += len(comments)\n",
    "        print(\"\\rRetrieved comments: {} (Submissions: {}/{})\".format(total_comments, i, total_submissions), end=\"\")\n",
    "\n",
    "    print()\n",
    "\n",
    "def get_collection(subreddit, name):\n",
    "\n",
    "    _ = subreddit.title\n",
    "\n",
    "    submissions = getattr(subreddit, name)(limit=None)\n",
    "\n",
    "    collection = {}\n",
    "\n",
    "    # add subreddit info and date\n",
    "    collection[\"collection_name\"] = name\n",
    "    collection[\"subreddit\"] = copy_subreddit(vars(subreddit))\n",
    "    collection[\"date\"] = datetime.datetime.now().isoformat()\n",
    "\n",
    "    # retrieve submissions list\n",
    "    submission_list = retrieve_submissions(submissions)\n",
    "\n",
    "    # retrieve comments\n",
    "    retrieve_comments(collection, submission_list)\n",
    "\n",
    "    return collection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_collection_path(collection_dir, display_name, collection_name):\n",
    "    return os.path.join(collection_dir, \"{}_{}.json\".format(display_name, collection_name))\n",
    "\n",
    "def get_collections(display_name, names):\n",
    "\n",
    "    reddit_client = None\n",
    "    subreddit = None\n",
    "\n",
    "    os.makedirs(collections_dir, exist_ok=True)\n",
    "\n",
    "    collections = {}\n",
    "\n",
    "    for collection_name in names:\n",
    "\n",
    "        collection_filename = get_collection_path(collections_dir, display_name, collection_name)\n",
    "\n",
    "        if os.path.isfile(collection_filename):\n",
    "            # read collection\n",
    "            print(\"Using saved collection: {}\".format(collection_filename))\n",
    "            with open(collection_filename) as collection_file:\n",
    "                collection = json.load(collection_file)\n",
    "\n",
    "            total_comments = 0\n",
    "            for submission in collection[\"submissions\"]:\n",
    "                total_comments += len(submission[\"comments\"])\n",
    "            print(\"  Submissions: {}, Comments: {}\".format(len(collection[\"submissions\"]), total_comments))\n",
    "\n",
    "        else:\n",
    "            # retrieve collection\n",
    "\n",
    "            if not reddit_client:\n",
    "                reddit_client = praw.Reddit(\"tgine\", user_agent=reddit_client_user_agent)\n",
    "                subreddit = reddit_client.subreddit(display_name)\n",
    "\n",
    "            collection = get_collection(subreddit, collection_name)\n",
    "\n",
    "            print(\"Saving collection: {}\".format(collection_filename))\n",
    "            with open(collection_filename, \"w\") as collection_file:\n",
    "                json.dump(collection, collection_file)\n",
    "\n",
    "        collections[collection_name] = collection\n",
    "\n",
    "    return collections"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_corpus(collections):\n",
    "\n",
    "    corpus = {}\n",
    "\n",
    "    for collection in collections:\n",
    "        corpus[collection] = []\n",
    "\n",
    "        for submission in collections[collection][\"submissions\"]:\n",
    "\n",
    "            corpus[collection].append(\"{} {}\".format(submission[\"submission\"][\"title\"],\n",
    "                                                     submission[\"submission\"][\"selftext\"]))\n",
    "\n",
    "            for comment in submission[\"comments\"]:\n",
    "\n",
    "                # AutoModerator is a bot discard its messages\n",
    "                if not comment[\"author\"] == \"AutoModerator\":\n",
    "                    corpus[collection].append(comment[\"body\"])\n",
    "\n",
    "    return corpus"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subreddit_collections = get_collections(subreddit_display_name, collection_names)\n",
    "collections_corpus = extract_corpus(subreddit_collections)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def print_central_repeated(corpus, min_doc_freq, most_central, most_rep):\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\", min_df=min_doc_freq, max_features=most_rep)\n",
    "    tfidf = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    most_repeated_terms = vectorizer.get_feature_names()\n",
    "\n",
    "    central_terms_score = np.sum(tfidf.toarray(), axis=0)\n",
    "    central_terms_indexes = np.argsort(central_terms_score)[-most_central:]\n",
    "    central_terms = [most_repeated_terms[i] for i in central_terms_indexes]\n",
    "    central_terms.reverse()\n",
    "\n",
    "    print(\"{} most central terms\".format(most_central))\n",
    "    pprint(central_terms, width=100, compact=True)\n",
    "    print()\n",
    "\n",
    "    print(\"{} most repeated terms\".format(most_rep))\n",
    "    pprint(most_repeated_terms, width=100, compact=True)\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for collection_corpus in collections_corpus:\n",
    "\n",
    "    print(\"Collection: {}\".format(collection_corpus))\n",
    "    print_central_repeated(collections_corpus[collection_corpus], min_document_frequency, most_central_terms, most_repeated)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def add_collections(writer, collections):\n",
    "\n",
    "    total_submissions = 0\n",
    "    submissions = 0\n",
    "    for collection in collections:\n",
    "        total_submissions += len(collections[collection][\"submissions\"])\n",
    "\n",
    "    for collection in collections:\n",
    "        for submission in collections[collection][\"submissions\"]:\n",
    "\n",
    "            writer.add_document(collection=collection,\n",
    "                                submission_id=submission[\"submission\"][\"id\"],\n",
    "                                author=submission[\"submission\"][\"author\"],\n",
    "                                content=\"{}\\n{}\".format(submission[\"submission\"][\"title\"],\n",
    "                                                        submission[\"submission\"][\"selftext\"]),\n",
    "                                is_submission=True)\n",
    "\n",
    "            total_comments = len(submission[\"comments\"])\n",
    "            comments = 0\n",
    "            submissions += 1\n",
    "\n",
    "            for comment in submission[\"comments\"]:\n",
    "                writer.add_document(collection=collection,\n",
    "                                    submission_id=submission[\"submission\"][\"id\"],\n",
    "                                    author=comment[\"author\"],\n",
    "                                    content=comment[\"body\"],\n",
    "                                    is_submission=False)\n",
    "\n",
    "                comments += 1\n",
    "                print(\"\\rIndexed: Submissions {}/{}; Comments {}/{}               \".format(submissions,\n",
    "                                                                                           total_submissions,\n",
    "                                                                                           comments,\n",
    "                                                                                           total_comments), end=\"\")\n",
    "    print()\n",
    "\n",
    "def get_index(index_path, collections):\n",
    "\n",
    "    if os.path.exists(index_path):\n",
    "        print(\"Using saved index: {}\".format(index_path))\n",
    "        return open_dir(index_path)\n",
    "\n",
    "    print(\"Creating index: {}\".format(index_path))\n",
    "    os.mkdir(index_path)\n",
    "\n",
    "    schema = Schema(collection=TEXT(stored=True),\n",
    "                    submission_id=ID(stored=True),\n",
    "                    author=TEXT(stored=True),\n",
    "                    content=TEXT(stored=True),\n",
    "                    is_submission=BOOLEAN(stored=True))\n",
    "\n",
    "    index = create_in(index_path, schema)\n",
    "\n",
    "    writer = index.writer()\n",
    "    add_collections(writer, collections)\n",
    "    writer.commit()\n",
    "\n",
    "    return index\n",
    "\n",
    "def print_results(results):\n",
    "\n",
    "    print(\"Search runtime: {}\".format(results.runtime))\n",
    "    print(\"Total results: {} (showing {})\\n\".format(results.estimated_length(),\n",
    "                                                    results.scored_length()))\n",
    "\n",
    "    for result in results:\n",
    "        print(\"{:<20}{}\".format(result[\"author\"], result[\"content\"].strip()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "collections_index = get_index(\"index\", subreddit_collections)\n",
    "index_searcher = collections_index.searcher()\n",
    "query_parser = QueryParser(\"content\", collections_index.schema)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query_str = \"scientists is_submission:true\"\n",
    "\n",
    "query = query_parser.parse(query_str)\n",
    "search_results = index_searcher.search(query)\n",
    "print_results(search_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "index_searcher.close()\n",
    "collections_index.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}